{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3d6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from typing import Any, Dict\n",
    "from langchain.docstore.document import Document\n",
    "import requests\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pathlib\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "from pprint import pprint\n",
    "import openai\n",
    "from utils.helpers import get_secret\n",
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def get_secret(name):\n",
    "    if name in os.environ:\n",
    "        return os.environ[name]\n",
    "    return os.getenv(name)\n",
    "\n",
    "# create .env in project dir and set api keys there\n",
    "openai.api_key = get_secret('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26867f5b",
   "metadata": {},
   "source": [
    "## Collect docs from a random github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7f9c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '.'...\n"
     ]
    }
   ],
   "source": [
    "def get_github_docs(repo_owner, repo_name):\n",
    "    with tempfile.TemporaryDirectory() as d:\n",
    "        subprocess.check_call(\n",
    "            f\"git clone --depth 1 https://github.com/{repo_owner}/{repo_name}.git .\",\n",
    "            cwd=d,\n",
    "            shell=True,\n",
    "        )\n",
    "        git_sha = (\n",
    "            subprocess.check_output(\"git rev-parse HEAD\", shell=True, cwd=d)\n",
    "            .decode(\"utf-8\")\n",
    "            .strip()\n",
    "        )\n",
    "        repo_path = pathlib.Path(d)\n",
    "        markdown_files = list(repo_path.glob(\"*/*.md\")) + list(\n",
    "            repo_path.glob(\"*/*.mdx\")\n",
    "        )\n",
    "        for markdown_file in markdown_files:\n",
    "            with open(markdown_file, \"r\") as f:\n",
    "                relative_path = markdown_file.relative_to(repo_path)\n",
    "                github_url = f\"https://github.com/{repo_owner}/{repo_name}/blob/{git_sha}/{relative_path}\"\n",
    "                yield Document(page_content=f.read(), metadata={\"source\": github_url})\n",
    "\n",
    "sources = get_github_docs(\"yirenlu92\", \"deno-manual-forked\")\n",
    "\n",
    "source_chunks = []\n",
    "splitter = CharacterTextSplitter(separator=\" \", chunk_size=1024, chunk_overlap=0)\n",
    "for source in sources:\n",
    "    for chunk in splitter.split_text(source.page_content):\n",
    "        source_chunks.append(Document(page_content=chunk, metadata=source.metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3926996f",
   "metadata": {},
   "source": [
    "## Create vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e0ca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./deeplake/ loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uan/anaconda3/envs/agents/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.2) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in ./deeplake/ already exists, loading from the storage\n",
      "Dataset(path='./deeplake/', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape      dtype  compression\n",
      "  -------   -------    -------    -------  ------- \n",
      " embedding  generic  (634, 1536)  float32   None   \n",
      "    ids      text     (634, 1)      str     None   \n",
      " metadata    json     (634, 1)      str     None   \n",
      "   text      text     (634, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='./deeplake/', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape      dtype  compression\n",
      "  -------   -------    -------    -------  ------- \n",
      " embedding  generic  (951, 1536)  float32   None   \n",
      "    ids      text     (951, 1)      str     None   \n",
      " metadata    json     (951, 1)      str     None   \n",
      "   text      text     (951, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "\r"
     ]
    }
   ],
   "source": [
    "search_index = DeepLake.from_documents(source_chunks, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19236d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "prompt_template = \"\"\"Use the context below to write a 400 word blog post about the topic below:\n",
    "    Context: {context}\n",
    "    Topic: {topic}\n",
    "    Blog post:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"topic\"]\n",
    ")\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8331af3",
   "metadata": {},
   "source": [
    "## for doc in similar_docs: model(doc + \"environment variables\") \n",
    "## simply put: runs a batch of each most similar doc + topic name and returns a batch of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "132eb760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': '\\n\\nEnvironment variables are a great way to store and access sensitive information in your applications. They are also a great way to keep your codebase clean and organized. In this blog post, we\\'ll discuss how to use environment variables in Deno.\\n\\nDeno offers built-in support for environment variables with `Deno.env`. `Deno.env` has getter and setter methods that allow you to set and retrieve environment variables. Here is an example of how to use `Deno.env`:\\n\\n```ts\\nDeno.env.set(\"FIREBASE_API_KEY\", \"examplekey123\");\\nDeno.env.set(\"FIREBASE_AUTH_DOMAIN\", \"firebasedomain.com\");\\n\\nconsole.log(Deno.env.get(\"FIREBASE_API_KEY\")); // examplekey123\\nconsole.log(Deno.env.get(\"FIREBASE_AUTH_DOMAIN\")); // firebasedomain.com\\n```\\n\\nYou can also store environment variables in a `.env` file and retrieve them using `dotenv` in the standard library. To access the environment variables in'}, {'text': '\\n\\nEnvironment variables are a great way to store and access sensitive information in your applications. They are also useful for configuring applications and managing different environments. In this blog post, we\\'ll look at how to use environment variables in Deno.\\n\\nDeno offers built-in support for environment variables with `Deno.env`. This object has getter and setter methods that allow you to set and retrieve environment variables. Here is an example of how to use `Deno.env`:\\n\\n```ts\\nDeno.env.set(\"FIREBASE_API_KEY\", \"examplekey123\");\\nDeno.env.set(\"FIREBASE_AUTH_DOMAIN\", \"firebasedomain.com\");\\n\\nconsole.log(Deno.env.get(\"FIREBASE_API_KEY\")); // examplekey123\\nconsole.log(Deno.env.get(\"FIREBASE_AUTH_DOMAIN\")); // firebasedomain.com\\n```\\n\\nYou can also store environment variables in a `.env` file and access them using the `dotenv` module in the standard library. To access the environment variables in the `.'}]\n"
     ]
    }
   ],
   "source": [
    "def generate_blog_post(topic):\n",
    "    docs = search_index.similarity_search(topic, k=2)\n",
    "    inputs = [{\"context\": doc.page_content, \"topic\": topic} for doc in docs]\n",
    "    print(chain.apply(inputs))\n",
    "    \n",
    "generate_blog_post(\"environment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3309df",
   "metadata": {},
   "source": [
    "## Take Solidity repo and split it to docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45da3b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1191, which is longer than the specified 1024\n",
      "Created a chunk of size 1252, which is longer than the specified 1024\n",
      "Created a chunk of size 1118, which is longer than the specified 1024\n",
      "Created a chunk of size 1540, which is longer than the specified 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/2023-04-frankencoin-preprocessed loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in data/2023-04-frankencoin-preprocessed already exists, loading from the storage\n",
      "Dataset(path='data/2023-04-frankencoin-preprocessed', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape      dtype  compression\n",
      "  -------   -------    -------    -------  ------- \n",
      " embedding  generic  (819, 1536)  float32   None   \n",
      "    ids      text     (819, 1)      str     None   \n",
      " metadata    json     (819, 1)      str     None   \n",
      "   text      text     (819, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='data/2023-04-frankencoin-preprocessed', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape      dtype  compression\n",
      "  -------   -------    -------    -------  ------- \n",
      " embedding  generic  (888, 1536)  float32   None   \n",
      "    ids      text     (888, 1)      str     None   \n",
      " metadata    json     (888, 1)      str     None   \n",
      "   text      text     (888, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "\r"
     ]
    }
   ],
   "source": [
    "repo_dir = \"data/2023-04-frankencoin mini\"  # this is just an example, for full repo use: \"data/2023-04-frankencoin\"\n",
    "processed_repo_path = \"data/2023-04-frankencoin-preprocessed\"\n",
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(repo_dir):\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e: \n",
    "            pass\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
    "my_documents = text_splitter.split_documents(docs)\n",
    "db = DeepLake.from_documents(my_documents, embedding=OpenAIEmbeddings(), dataset_path=processed_repo_path) # saves to processed_repo_path\n",
    "# to load already preprocessed:\n",
    "# DeepLake(processed_repo_path, embedding_function=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd17294",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Gas optimize the solidity code surrounded by triple backticks:\n",
    "    Context: {context}\n",
    "    Solidity code: ```{solidity_code}```\n",
    "    Gas optimized solidity code:\"\"\"\n",
    "\n",
    "solidity_code = \"\"\"function loop(uint[] memory arr) external pure returns (uint sum) {\n",
    "    for (uint i = 0; i < arr.length; i++) {\n",
    "        sum += arr[i];\n",
    "    }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d804c83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': ' ```function loop(uint[] memory arr) external pure returns (uint sum) {\\n    uint length = arr.length;\\n    for (uint i = 0; i < length; i++) {\\n        sum += arr[i];\\n    }\\n}```'}, {'text': ' ```function loop(uint[] memory arr) external pure returns (uint sum) {\\n    uint length = arr.length;\\n    for (uint i = 0; i < length; i++) {\\n        sum += arr[i];\\n    }\\n}```'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"solidity_code\"]\n",
    ")\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n",
    "\n",
    "def optimize_solidity_code_with_vectore_store(vector_store, solidity_code):\n",
    "    docs = vector_store.similarity_search(solidity_code, k=2)\n",
    "    inputs = [{\"context\": doc.page_content, \"solidity_code\": solidity_code} for doc in docs]\n",
    "    print(chain.apply(inputs))\n",
    "    \n",
    "optimize_solidity_code_with_vectore_store(search_index, solidity_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d2a61",
   "metadata": {},
   "source": [
    "# How those docs look like inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff587fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "doc # 0:\n",
      "```\n",
      "\"./deps.ts\";\n",
      "\n",
      "function totalCost(outbound: number, inbound: number, tax: number): number {\n",
      " return multiply(add(outbound, inbound), tax);\n",
      "}\n",
      "\n",
      "console.log(totalCost(19, 31, 1.2));\n",
      "console.log(totalCost(45, 27, 1.15));\n",
      "\n",
      "/**\n",
      " * Output\n",
      " *\n",
      " * 60\n",
      " * 82.8\n",
      " */\n",
      "```\n",
      "```\n",
      "\n",
      "doc # 1:\n",
      "```\n",
      "\"./deps.ts\";\n",
      "\n",
      "function totalCost(outbound: number, inbound: number, tax: number): number {\n",
      " return multiply(add(outbound, inbound), tax);\n",
      "}\n",
      "\n",
      "console.log(totalCost(19, 31, 1.2));\n",
      "console.log(totalCost(45, 27, 1.15));\n",
      "\n",
      "/**\n",
      " * Output\n",
      " *\n",
      " * 60\n",
      " * 82.8\n",
      " */\n",
      "```\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = search_index.similarity_search(solidity_code, k=2)\n",
    "\n",
    "print(len(docs))\n",
    "for i in range(len(docs)):\n",
    "    print(f\"doc # {i}:\\n```\\n{docs[i].page_content}\\n```\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5e4a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "class SolidityTextSplitter(RecursiveCharacterTextSplitter):\n",
    "    \"\"\"Attempts to split the text along Python syntax.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs: Any):\n",
    "        \"\"\"Initialize a MarkdownTextSplitter.\"\"\"\n",
    "        separators = [\n",
    "            # First, try to split along class definitions\n",
    "            \"\\ncontract \",\n",
    "            \"\\nfunction \",\n",
    "            \"\\n\\tfunction \",\n",
    "            \"\\nconstructor \",\n",
    "            \"\\n\\tconstructor \",\n",
    "            \"\\nmodifier \",\n",
    "            \"\\n\\tmodifier \",\n",
    "            # Now split by the normal type of lines\n",
    "            \"\\n\\n\",\n",
    "            \"\\n\",\n",
    "            \" \",\n",
    "            \"\",\n",
    "        ]\n",
    "        super().__init__(separators=separators, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "020d53fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/2023-04-frankencoin-preprocessed loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in data/2023-04-frankencoin-preprocessed already exists, loading from the storage\n",
      "Dataset(path='data/2023-04-frankencoin-preprocessed', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape      dtype  compression\n",
      "  -------   -------    -------    -------  ------- \n",
      " embedding  generic  (817, 1536)  float32   None   \n",
      "    ids      text     (817, 1)      str     None   \n",
      " metadata    json     (817, 1)      str     None   \n",
      "   text      text     (817, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='data/2023-04-frankencoin-preprocessed', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype      shape      dtype  compression\n",
      "  -------   -------    -------    -------  ------- \n",
      " embedding  generic  (819, 1536)  float32   None   \n",
      "    ids      text     (819, 1)      str     None   \n",
      " metadata    json     (819, 1)      str     None   \n",
      "   text      text     (819, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "\r"
     ]
    }
   ],
   "source": [
    "text_splitter = SolidityTextSplitter(chunk_size=300, chunk_overlap=0, length_function = len)\n",
    "my_documents = text_splitter.split_documents(docs)\n",
    "better_search_index = DeepLake.from_documents(my_documents, embedding=OpenAIEmbeddings(), dataset_path=processed_repo_path) # saves to processed_repo_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66f48fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of retrieved docs: 2\n",
      "doc # 0:\n",
      "\n",
      "function votes(address sender, address[] calldata helpers) public view returns (uint256) {\n",
      "        uint256 _votes = votes(sender);\n",
      "        for (uint i=0; i<helpers.length; i++){\n",
      "            address current = helpers[i];\n",
      "            require(current != sender);\n",
      "            require(canVoteFor(sender, current));\n",
      "            for (uint j=i+1; j<helpers.length; j++){\n",
      "                require(current != helpers[j]); // ensure helper unique\n",
      "            }\n",
      "            _votes += votes(current);\n",
      "        }\n",
      "        return _votes;\n",
      "    }\n",
      "\n",
      "\n",
      "doc # 1:\n",
      "\n",
      "function votes(address sender, address[] calldata helpers) public view returns (uint256) {\n",
      "        uint256 _votes = votes(sender);\n",
      "        for (uint i=0; i<helpers.length; i++){\n",
      "            address current = helpers[i];\n",
      "            require(current != sender);\n",
      "            require(canVoteFor(sender, current));\n",
      "            for (uint j=i+1; j<helpers.length; j++){\n",
      "                require(current != helpers[j]); // ensure helper unique\n",
      "            }\n",
      "            _votes += votes(current);\n",
      "        }\n",
      "        return _votes;\n",
      "    }\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = better_search_index.similarity_search(solidity_code, k=2)\n",
    "print(f\"number of retrieved docs: {len(docs)}\")\n",
    "for i in range(len(docs)):\n",
    "    print(f\"doc # {i}:\\n\\n{docs[i].page_content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0086f825",
   "metadata": {},
   "source": [
    "## Compound docs and pass to input with original Solidity code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ee1477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.keys(): dict_keys(['context', 'solidity_code', 'text'])\n",
      "{'context': 'function votes(address sender, address[] calldata helpers) public '\n",
      "            'view returns (uint256) {\\n'\n",
      "            '        uint256 _votes = votes(sender);\\n'\n",
      "            '        for (uint i=0; i<helpers.length; i++){\\n'\n",
      "            '            address current = helpers[i];\\n'\n",
      "            '            require(current != sender);\\n'\n",
      "            '            require(canVoteFor(sender, current));\\n'\n",
      "            '            for (uint j=i+1; j<helpers.length; j++){\\n'\n",
      "            '                require(current != helpers[j]); // ensure helper '\n",
      "            'unique\\n'\n",
      "            '            }\\n'\n",
      "            '            _votes += votes(current);\\n'\n",
      "            '        }\\n'\n",
      "            '        return _votes;\\n'\n",
      "            '    }\\n'\n",
      "            'function votes(address sender, address[] calldata helpers) public '\n",
      "            'view returns (uint256) {\\n'\n",
      "            '        uint256 _votes = votes(sender);\\n'\n",
      "            '        for (uint i=0; i<helpers.length; i++){\\n'\n",
      "            '            address current = helpers[i];\\n'\n",
      "            '            require(current != sender);\\n'\n",
      "            '            require(canVoteFor(sender, current));\\n'\n",
      "            '            for (uint j=i+1; j<helpers.length; j++){\\n'\n",
      "            '                require(current != helpers[j]); // ensure helper '\n",
      "            'unique\\n'\n",
      "            '            }\\n'\n",
      "            '            _votes += votes(current);\\n'\n",
      "            '        }\\n'\n",
      "            '        return _votes;\\n'\n",
      "            '    }',\n",
      " 'solidity_code': 'function loop(uint[] memory arr) external pure returns '\n",
      "                  '(uint sum) {\\n'\n",
      "                  '    for (uint i = 0; i < arr.length; i++) {\\n'\n",
      "                  '        sum += arr[i];\\n'\n",
      "                  '    }\\n'\n",
      "                  '}',\n",
      " 'text': ' ```function loop(uint[] memory arr) external pure returns (uint '\n",
      "         'sum) {\\n'\n",
      "         '    uint length = arr.length;\\n'\n",
      "         '    for (uint i = 0; i < length; i++) {\\n'\n",
      "         '        sum += arr[i];\\n'\n",
      "         '    }\\n'\n",
      "         '}```'}\n"
     ]
    }
   ],
   "source": [
    "def optimize_solidity_code_with_vectore_store(vector_store, solidity_code):\n",
    "    docs = vector_store.similarity_search(solidity_code, k=2)\n",
    "    context = '\\n'.join([doc.page_content for doc in docs])\n",
    "#     chain.apply(inputs)\n",
    "    result = chain({\"context\": context, \"solidity_code\": solidity_code})\n",
    "    print(f\"result.keys(): {result.keys()}\")\n",
    "    pprint(result)\n",
    "    \n",
    "optimize_solidity_code_with_vectore_store(better_search_index, solidity_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e76c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786293c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64647798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
